{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis with Python\n",
    "\n",
    "We will explore the NYC MTA turnstile data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "- Download a few [MTA turnstile data files](http://web.mta.info/developers/turnstile.html)\n",
    "- Open up a file, use csv reader to read it, make a python dict where there is a key for each (C/A, UNIT, SCP, STATION). These are the first four columns. The value for this key should be a list of lists. Each list in the list is the rest of the columns in a row. For example, one key-value pair should look like\n",
    "\n",
    "\n",
    "        {    ('A002','R051','02-00-00','LEXINGTON AVE'):    \n",
    "             [\n",
    "               ['NQR456', 'BMT', '01/03/2015', '03:00:00', 'REGULAR', '0004945474', '0001675324'],          \n",
    "                 ['NQR456', 'BMT', '01/03/2015', '07:00:00', 'REGULAR', '0004945478', '0001675333'],  \n",
    "                ['NQR456', 'BMT', '01/03/2015', '11:00:00', 'REGULAR', '0004945515', '0001675364'],\n",
    "              ...   \n",
    "         ] \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-01-21 18:18:23--  http://web.mta.info/developers/data/nyct/turnstile/turnstile_150124.txt\n",
      "Resolving web.mta.info... 23.67.251.41, 23.67.251.74\n",
      "Connecting to web.mta.info|23.67.251.41|:80... connected.\n",
      "HTTP request sent, awaiting response... \n",
      "  HTTP/1.1 200 OK\n",
      "  Server: Oracle-iPlanet-Web-Server/7.0\n",
      "  Content-Type: text/plain\n",
      "  Last-Modified: Sat, 24 Jan 2015 10:12:04 GMT\n",
      "  ETag: W/\"1818a44-54c36ff4\"\n",
      "  Vary: Accept-Encoding\n",
      "  Date: Sat, 21 Jan 2017 23:18:25 GMT\n",
      "  Transfer-Encoding:  chunked\n",
      "  Connection: keep-alive\n",
      "  Connection: Transfer-Encoding\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: ‘turnstile_150124.txt’\n",
      "\n",
      "turnstile_150124.tx     [               <=>  ]  24.10M  8.54MB/s    in 2.8s    \n",
      "\n",
      "2017-01-21 18:18:27 (8.54 MB/s) - ‘turnstile_150124.txt’ saved [25266756]\n",
      "\n",
      "--2017-01-21 18:18:28--  http://web.mta.info/developers/data/nyct/turnstile/turnstile_150117.txt\n",
      "Resolving web.mta.info... 23.67.251.41, 23.67.251.74\n",
      "Connecting to web.mta.info|23.67.251.41|:80... connected.\n",
      "HTTP request sent, awaiting response... \n",
      "  HTTP/1.1 200 OK\n",
      "  Server: Oracle-iPlanet-Web-Server/7.0\n",
      "  Content-Type: text/plain\n",
      "  Last-Modified: Sat, 17 Jan 2015 10:08:38 GMT\n",
      "  ETag: W/\"192403c-54ba34a6\"\n",
      "  Vary: Accept-Encoding\n",
      "  Date: Sat, 21 Jan 2017 23:18:28 GMT\n",
      "  Transfer-Encoding:  chunked\n",
      "  Connection: keep-alive\n",
      "  Connection: Transfer-Encoding\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: ‘turnstile_150117.txt’\n",
      "\n",
      "turnstile_150117.tx     [         <=>        ]  25.14M  1.53MB/s    in 17s     \n",
      "\n",
      "2017-01-21 18:18:45 (1.49 MB/s) - ‘turnstile_150117.txt’ saved [26361916]\n",
      "\n",
      "--2017-01-21 18:18:45--  http://web.mta.info/developers/data/nyct/turnstile/turnstile_150110.txt\n",
      "Resolving web.mta.info... 162.216.59.40, 162.216.59.48\n",
      "Connecting to web.mta.info|162.216.59.40|:80... connected.\n",
      "HTTP request sent, awaiting response... \n",
      "  HTTP/1.1 200 OK\n",
      "  Server: Oracle-iPlanet-Web-Server/7.0\n",
      "  Content-Type: text/plain\n",
      "  Last-Modified: Sat, 10 Jan 2015 10:06:09 GMT\n",
      "  ETag: W/\"186ca8d-54b0f991\"\n",
      "  Vary: Accept-Encoding\n",
      "  Date: Sat, 21 Jan 2017 23:18:46 GMT\n",
      "  Transfer-Encoding:  chunked\n",
      "  Connection: keep-alive\n",
      "  Connection: Transfer-Encoding\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: ‘turnstile_150110.txt’\n",
      "\n",
      "turnstile_150110.tx     [          <=>       ]  24.42M  1.51MB/s    in 17s     \n",
      "\n",
      "2017-01-21 18:19:02 (1.47 MB/s) - ‘turnstile_150110.txt’ saved [25610893]\n",
      "\n",
      "--2017-01-21 18:19:03--  http://web.mta.info/developers/data/nyct/turnstile/turnstile_150103.txt\n",
      "Resolving web.mta.info... 162.216.59.40, 162.216.59.48\n",
      "Connecting to web.mta.info|162.216.59.40|:80... connected.\n",
      "HTTP request sent, awaiting response... \n",
      "  HTTP/1.1 200 OK\n",
      "  Server: Oracle-iPlanet-Web-Server/7.0\n",
      "  Content-Type: text/plain\n",
      "  Last-Modified: Thu, 08 Jan 2015 16:35:54 GMT\n",
      "  ETag: W/\"18403c6-54aeb1ea\"\n",
      "  Vary: Accept-Encoding\n",
      "  Date: Sat, 21 Jan 2017 23:19:03 GMT\n",
      "  Transfer-Encoding:  chunked\n",
      "  Connection: keep-alive\n",
      "  Connection: Transfer-Encoding\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: ‘turnstile_150103.txt’\n",
      "\n",
      "turnstile_150103.tx     [           <=>      ]  24.25M  1.50MB/s    in 16s     \n",
      "\n",
      "2017-01-21 18:19:20 (1.48 MB/s) - ‘turnstile_150103.txt’ saved [25428934]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url_template = 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_%s.txt'\n",
    "for date in ['150124', '150117', '150110', '150103']:\n",
    "    url = url_template % date\n",
    "    !wget {url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv, glob\n",
    "from collections import defaultdict\n",
    "\n",
    "def read_csv(csv_file_name):\n",
    "\n",
    "    turnstile_to_count_reading = defaultdict(list)\n",
    "    with open(csv_file_name, 'r') as csv_file:\n",
    "        mta_reader = csv.reader(csv_file)\n",
    "        for i, row in enumerate(mta_reader):\n",
    "            # skip the first row, it's just header strings\n",
    "            if i == 0:\n",
    "                continue\n",
    "            # read the rest\n",
    "            turnstile_info = tuple(row[:4])\n",
    "            count_reading = row[4:]\n",
    "            turnstile_to_count_reading[turnstile_info].append(count_reading)\n",
    "    return turnstile_to_count_reading\n",
    "\n",
    "\n",
    "#A) List comprehension\n",
    "weekly_data_dicts = [read_csv(csvfile) for csvfile in glob.glob(\"turnstile_*.txt\")]\n",
    "\n",
    "#B) Alternatively, map\n",
    "# data_files = glob.glob(\"turnstile_*.txt\")\n",
    "# weekly_data_dicts = map(read_csv, data_files)\n",
    "\n",
    "#C) Alternatively, separating the steps on multiple lines\n",
    "#weekly_data_dicts = []\n",
    "#for data_file in glob.glob(\"turnstile_*.txt\"):\n",
    "#    print 'Processing %s' % data_file\n",
    "#    weekly_data_dicts.append(read_csv(data_file))\n",
    "    \n",
    "#(Choose the approach you find more readable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('R208', 'R014', '03-00-00', 'FULTON ST'),\n",
      "  [['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/27/2014',\n",
      "    '00:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282065',\n",
      "    '0006891794                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/27/2014',\n",
      "    '04:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282066',\n",
      "    '0006891795                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/27/2014',\n",
      "    '08:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282066',\n",
      "    '0006891802                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/27/2014',\n",
      "    '12:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282073',\n",
      "    '0006891861                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/27/2014',\n",
      "    '16:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282086',\n",
      "    '0006891911                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/27/2014',\n",
      "    '20:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282086',\n",
      "    '0006891911                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/28/2014',\n",
      "    '00:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282086',\n",
      "    '0006891911                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/28/2014',\n",
      "    '04:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282086',\n",
      "    '0006891911                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/28/2014',\n",
      "    '08:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282086',\n",
      "    '0006891911                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/28/2014',\n",
      "    '12:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282087',\n",
      "    '0006891937                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/28/2014',\n",
      "    '16:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282096',\n",
      "    '0006891977                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/28/2014',\n",
      "    '20:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282103',\n",
      "    '0006891997                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/29/2014',\n",
      "    '00:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282105',\n",
      "    '0006892000                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/29/2014',\n",
      "    '04:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282105',\n",
      "    '0006892001                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/29/2014',\n",
      "    '08:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282111',\n",
      "    '0006892031                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/29/2014',\n",
      "    '12:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282126',\n",
      "    '0006892187                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/29/2014',\n",
      "    '16:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282152',\n",
      "    '0006892293                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/29/2014',\n",
      "    '20:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282190',\n",
      "    '0006892385                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/30/2014',\n",
      "    '00:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282192',\n",
      "    '0006892399                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/30/2014',\n",
      "    '04:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282192',\n",
      "    '0006892404                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/30/2014',\n",
      "    '08:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282204',\n",
      "    '0006892447                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/30/2014',\n",
      "    '12:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282219',\n",
      "    '0006892575                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/30/2014',\n",
      "    '16:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282240',\n",
      "    '0006892652                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/30/2014',\n",
      "    '20:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282265',\n",
      "    '0006892752                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/31/2014',\n",
      "    '00:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282273',\n",
      "    '0006892765                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/31/2014',\n",
      "    '04:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282275',\n",
      "    '0006892766                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/31/2014',\n",
      "    '08:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282278',\n",
      "    '0006892798                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/31/2014',\n",
      "    '12:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282290',\n",
      "    '0006892897                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/31/2014',\n",
      "    '16:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282318',\n",
      "    '0006892960                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '12/31/2014',\n",
      "    '20:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282340',\n",
      "    '0006893028                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '01/01/2015',\n",
      "    '00:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282344',\n",
      "    '0006893066                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '01/01/2015',\n",
      "    '04:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282344',\n",
      "    '0006893078                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '01/01/2015',\n",
      "    '08:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282344',\n",
      "    '0006893084                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '01/01/2015',\n",
      "    '12:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282347',\n",
      "    '0006893104                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '01/01/2015',\n",
      "    '16:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282356',\n",
      "    '0006893148                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '01/01/2015',\n",
      "    '20:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282361',\n",
      "    '0006893182                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '01/02/2015',\n",
      "    '00:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282366',\n",
      "    '0006893190                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '01/02/2015',\n",
      "    '04:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282367',\n",
      "    '0006893192                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '01/02/2015',\n",
      "    '08:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282368',\n",
      "    '0006893218                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '01/02/2015',\n",
      "    '12:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282393',\n",
      "    '0006893335                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '01/02/2015',\n",
      "    '16:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282411',\n",
      "    '0006893418                                       '],\n",
      "   ['2345ACJZ',\n",
      "    'IRT',\n",
      "    '01/02/2015',\n",
      "    '20:00:00',\n",
      "    'REGULAR',\n",
      "    '0010282425',\n",
      "    '0006893483                                       ']]),\n",
      " (('N112A', 'R284', '01-00-01', 'CLINTON-WASH AV'),\n",
      "  [['C',\n",
      "    'IND',\n",
      "    '12/27/2014',\n",
      "    '03:00:00',\n",
      "    'REGULAR',\n",
      "    '0000307917',\n",
      "    '0001027633                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/27/2014',\n",
      "    '07:00:00',\n",
      "    'REGULAR',\n",
      "    '0000307924',\n",
      "    '0001027646                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/27/2014',\n",
      "    '11:00:00',\n",
      "    'REGULAR',\n",
      "    '0000307939',\n",
      "    '0001027673                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/27/2014',\n",
      "    '15:00:00',\n",
      "    'REGULAR',\n",
      "    '0000307964',\n",
      "    '0001027743                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/27/2014',\n",
      "    '19:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308006',\n",
      "    '0001027862                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/27/2014',\n",
      "    '23:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308032',\n",
      "    '0001028000                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/28/2014',\n",
      "    '03:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308049',\n",
      "    '0001028100                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/28/2014',\n",
      "    '07:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308055',\n",
      "    '0001028126                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/28/2014',\n",
      "    '11:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308074',\n",
      "    '0001028154                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/28/2014',\n",
      "    '15:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308105',\n",
      "    '0001028211                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/28/2014',\n",
      "    '19:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308163',\n",
      "    '0001028354                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/28/2014',\n",
      "    '23:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308195',\n",
      "    '0001028453                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/29/2014',\n",
      "    '03:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308205',\n",
      "    '0001028506                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/29/2014',\n",
      "    '07:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308215',\n",
      "    '0001028521                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/29/2014',\n",
      "    '11:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308256',\n",
      "    '0001028584                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/29/2014',\n",
      "    '15:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308299',\n",
      "    '0001028677                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/29/2014',\n",
      "    '19:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308386',\n",
      "    '0001028941                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/29/2014',\n",
      "    '23:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308427',\n",
      "    '0001029175                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/30/2014',\n",
      "    '03:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308446',\n",
      "    '0001029240                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/30/2014',\n",
      "    '07:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308454',\n",
      "    '0001029248                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/30/2014',\n",
      "    '11:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308486',\n",
      "    '0001029315                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/30/2014',\n",
      "    '15:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308537',\n",
      "    '0001029408                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/30/2014',\n",
      "    '19:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308629',\n",
      "    '0001029732                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/30/2014',\n",
      "    '23:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308693',\n",
      "    '0001029988                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/31/2014',\n",
      "    '03:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308707',\n",
      "    '0001030080                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/31/2014',\n",
      "    '07:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308718',\n",
      "    '0001030096                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/31/2014',\n",
      "    '11:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308745',\n",
      "    '0001030170                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/31/2014',\n",
      "    '15:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308792',\n",
      "    '0001030311                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/31/2014',\n",
      "    '19:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308863',\n",
      "    '0001030644                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '12/31/2014',\n",
      "    '23:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308934',\n",
      "    '0001030856                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '01/01/2015',\n",
      "    '03:00:00',\n",
      "    'REGULAR',\n",
      "    '0000308982',\n",
      "    '0001031024                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '01/01/2015',\n",
      "    '07:00:00',\n",
      "    'REGULAR',\n",
      "    '0000309003',\n",
      "    '0001031073                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '01/01/2015',\n",
      "    '11:00:00',\n",
      "    'REGULAR',\n",
      "    '0000309013',\n",
      "    '0001031089                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '01/01/2015',\n",
      "    '15:00:00',\n",
      "    'REGULAR',\n",
      "    '0000309052',\n",
      "    '0001031140                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '01/01/2015',\n",
      "    '19:00:00',\n",
      "    'REGULAR',\n",
      "    '0000309101',\n",
      "    '0001031264                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '01/01/2015',\n",
      "    '23:00:00',\n",
      "    'REGULAR',\n",
      "    '0000309134',\n",
      "    '0001031401                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '01/02/2015',\n",
      "    '03:00:00',\n",
      "    'REGULAR',\n",
      "    '0000309148',\n",
      "    '0001031468                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '01/02/2015',\n",
      "    '07:00:00',\n",
      "    'REGULAR',\n",
      "    '0000309157',\n",
      "    '0001031477                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '01/02/2015',\n",
      "    '11:00:00',\n",
      "    'REGULAR',\n",
      "    '0000309198',\n",
      "    '0001031524                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '01/02/2015',\n",
      "    '15:00:00',\n",
      "    'REGULAR',\n",
      "    '0000309244',\n",
      "    '0001031641                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '01/02/2015',\n",
      "    '19:00:00',\n",
      "    'REGULAR',\n",
      "    '0000309340',\n",
      "    '0001031904                                       '],\n",
      "   ['C',\n",
      "    'IND',\n",
      "    '01/02/2015',\n",
      "    '23:00:00',\n",
      "    'REGULAR',\n",
      "    '0000309386',\n",
      "    '0001032107                                       ']])]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# just get 2 keys from the first dict to now overwhelm the output\n",
    "sample_dict = list(weekly_data_dicts[0].items())[:2]\n",
    "pprint(sample_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "- Let's turn this into a time series.\n",
    "\n",
    " For each key (basically the control area, unit, device address and station of a specific turnstile), have a list again, but let the list be comprised of just the point in time and the cumulative count of entries.\n",
    "\n",
    "This basically means keeping only the date, time, and entries fields in each list. You can convert the date and time into datetime objects -- That is a python class that represents a point in time. You can combine the date and time fields into a string and use the [dateutil](https://dateutil.readthedocs.io/en/stable/) module to convert it into a datetime object.\n",
    "\n",
    "Your new dict should look something like\n",
    " \n",
    "    {    ('A002','R051','02-00-00','LEXINGTON AVE'):    \n",
    "             [\n",
    "                [datetime.datetime(2013, 3, 2, 3, 0), 3788],\n",
    "                [datetime.datetime(2013, 3, 2, 7, 0), 2585],\n",
    "                [datetime.datetime(2013, 3, 2, 12, 0), 10653],\n",
    "                [datetime.datetime(2013, 3, 2, 17, 0), 11016],\n",
    "                [datetime.datetime(2013, 3, 2, 23, 0), 10666],\n",
    "                [datetime.datetime(2013, 3, 3, 3, 0), 10814],\n",
    "                [datetime.datetime(2013, 3, 3, 7, 0), 10229],\n",
    "                ...\n",
    "              ],\n",
    "     ....\n",
    "     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weekly_time_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-39cc36da0722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mturnstile_to_full_time_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_multiple_weeks_into_single_high_res_timeseries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweekly_time_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mturnstile_to_daily_time_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_turnstile_to_high_res_time_series_to_daily\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturnstile_to_full_time_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weekly_time_series' is not defined"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "def count_within_normal_bounds(count):\n",
    "    if count is None:\n",
    "        return True\n",
    "    else:\n",
    "        return 10000 > count >= 0\n",
    "\n",
    "def convert_time_series_to_daily(high_res_time_series):\n",
    "    daily_time_series = []\n",
    "    # I can define a function WITHIN another function. It will only\n",
    "    # be defined within the scope of the mother function\n",
    "    def day_of_timestamp(time_series_entry):\n",
    "        timestamp, tot_entries = time_series_entry\n",
    "        # the .date() method of a datetime object returns the day\n",
    "        #(as another datetime object)\n",
    "        return timestamp.date()\n",
    "    # groupby() requires data to be sorted. It is sorted already here,\n",
    "    # but if it wasn't, we would have to sort it first\n",
    "    count_on_previous_day = None\n",
    "    for day, entries_on_this_day in groupby(high_res_time_series,\n",
    "                                                      key=day_of_timestamp):\n",
    "        # get the maximum cumulative count among the entries on this day\n",
    "        cum_entry_count_on_day = max([count for time, count in entries_on_this_day])\n",
    "        # skip the first entry if we don't know the previous day\n",
    "        if count_on_previous_day is None:\n",
    "            daily_entries = None\n",
    "        else:\n",
    "            daily_entries = cum_entry_count_on_day - count_on_previous_day\n",
    "        # Save today's count for tomorrow's calculation\n",
    "        count_on_previous_day = cum_entry_count_on_day\n",
    "        # Only append if the cumulative increased. Otherwise there is something wrong in the data\n",
    "        # skip with a warning\n",
    "        if count_within_normal_bounds(daily_entries):\n",
    "            daily_time_series.append( (day, daily_entries) )\n",
    "        else:\n",
    "            print ('WARNING. Abnormal entry count found '\n",
    "                   'on day %s: %s' % (day, daily_entries))\n",
    "            daily_time_series.append( (day, None) )\n",
    "\n",
    "    return daily_time_series\n",
    "\n",
    "\n",
    "def combine_multiple_weeks_into_single_high_res_timeseries(weekly_time_series):\n",
    "    combined_time_series = defaultdict(list)\n",
    "    for turnstile_to_weeklong_time_series in weekly_time_series:\n",
    "        for turnstile, weeklong_time_series in turnstile_to_weeklong_time_series.items():\n",
    "            combined_time_series[turnstile] += weeklong_time_series\n",
    "    # It's already sorted due to the nature of the files but if not you would want to sort\n",
    "    # the dates first before retiurning it\n",
    "    return combined_time_series\n",
    "\n",
    "\n",
    "def convert_turnstile_to_high_res_time_series_to_daily(turnstile_to_time_series):\n",
    "    turnstile_to_daily_time_series = {}\n",
    "    for i, (turnstile, time_series) in enumerate(turnstile_to_time_series.items()):\n",
    "        print('Processing turnstile', turnstile)\n",
    "        turnstile_to_daily_time_series[turnstile] = convert_time_series_to_daily(time_series)\n",
    "    return turnstile_to_daily_time_series\n",
    "\n",
    "\n",
    "turnstile_to_full_time_series = combine_multiple_weeks_into_single_high_res_timeseries(weekly_time_series)\n",
    "turnstile_to_daily_time_series = convert_turnstile_to_high_res_time_series_to_daily(turnstile_to_full_time_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def convert_week_data_to_time_series(week_data_dict):\n",
    "    turnstile_to_time_series = defaultdict(list)\n",
    "    for i, (turnstile, row_data) in enumerate(week_data_dict.items()):\n",
    "        # report every 100 turnstiles\n",
    "        if i%100 == 0:\n",
    "            print('Processing turnstile', turnstile)\n",
    "        for lines, division, datestr, timestr, event, cum_entries, cum_exits in row_data:\n",
    "            timestamp = parse('%sT%s' % (datestr,timestr))\n",
    "            turnstile_to_time_series[turnstile].append([timestamp, int(cum_entries)])\n",
    "    return turnstile_to_time_series\n",
    "\n",
    "\n",
    "# this takes a while\n",
    "weekly_time_series = list(map(convert_week_data_to_time_series, weekly_data_dicts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking the result\n",
    "# just get 2 keys from the first dict to now overwhelm the output\n",
    "sample_turnstile_to_time_series = list(weekly_time_series[0].items())[:2]\n",
    "pprint(sample_turnstile_to_time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3\n",
    "- These counts are cumulative every n hours. We want total daily entries. \n",
    "\n",
    "Now make it that we again have the same keys, but now we have a single value for a single day, which is not cumulative counts but the total number of passengers that entered through this turnstile on this day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's check\n",
    "pprint( turnstile_to_daily_time_series[('N507', 'R023', '00-00-03', '34 ST-HERALD SQ')] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4\n",
    "- We will plot the daily time series for a turnstile.\n",
    "\n",
    "In ipython notebook, add this to the beginning of your next cell:    \n",
    "\n",
    "    %matplotlib inline\n",
    "\n",
    "This will make your matplotlib graphs integrate nicely with the notebook.\n",
    "To plot the time series, import matplotlib with \n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "Take the list of [(date1, count1), (date2, count2), ...], for the turnstile and turn it into two lists:\n",
    "dates and counts. This should plot it:\n",
    "\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.plot(dates,counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "time_series = turnstile_to_daily_time_series[('A030', 'R083', '01-06-00', '23 ST-5 AVE')]\n",
    "days, counts = zip(*time_series)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(days,counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 5\n",
    "- So far we've been operating on a single turnstile level, let's combine turnstiles in the same ControlArea/Unit/Station combo. There are some ControlArea/Unit/Station groups that have a single turnstile, but most have multiple turnstilea-- same value for the C/A, UNIT and STATION columns, different values for the SCP column.\n",
    "\n",
    "We want to combine the numbers together -- for each ControlArea/UNIT/STATION combo, for each day, add the counts from each turnstile belonging to that combo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def booth_of_a_turnstile(turnstile):\n",
    "    control_area, unit, device_id, station = turnstile\n",
    "    return (control_area, unit, station)\n",
    "\n",
    "def booth_of_a_time_series_item(item):\n",
    "    turnstile, time_series = item\n",
    "    return booth_of_a_turnstile(turnstile)\n",
    "\n",
    "def reduce_turnstile_time_series_to_booths(turnstile_to_daily_time_series):\n",
    "    turnstile_time_series_items = sorted(turnstile_to_daily_time_series.items())\n",
    "    booth_to_time_series = {}\n",
    "    for booth, item_list_of_booth in groupby(turnstile_time_series_items,\n",
    "                                             key=booth_of_a_time_series_item):\n",
    "        daily_counter = Counter()\n",
    "        for turnstile, time_series in item_list_of_booth:\n",
    "            for day, count in time_series:\n",
    "                if count is not None:\n",
    "                    daily_counter[day] += count\n",
    "                \n",
    "        booth_to_time_series[booth] = sorted(daily_counter.items())\n",
    "\n",
    "    return booth_to_time_series\n",
    "\n",
    "\n",
    "booth_to_daily_time_series = reduce_turnstile_time_series_to_booths(turnstile_to_daily_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check\n",
    "pprint(booth_to_daily_time_series[('A030', 'R083', '23 ST-5 AVE')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 6\n",
    "- Similarly, combine everything in each station, and come up with a time series of `[(date1, count1),(date2,count2),...]` type of time series for each STATION, by adding up all the turnstiles in a station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def station_of_a_booth(booth):\n",
    "    control_area, unit, station = booth\n",
    "    return station\n",
    "\n",
    "def station_of_a_time_series_item(item):\n",
    "    booth, time_series = item\n",
    "    return station_of_a_booth(booth)\n",
    "\n",
    "def reduce_booth_time_series_to_stations(booth_to_daily_time_series):\n",
    "    booth_time_series_items = sorted(booth_to_daily_time_series.items())\n",
    "    station_to_time_series = {}\n",
    "    for station, item_list_of_station in groupby(booth_time_series_items,\n",
    "                                             key=station_of_a_time_series_item):\n",
    "        daily_counter = Counter()\n",
    "        for turnstile, time_series in item_list_of_station:\n",
    "            for day, count in time_series:\n",
    "                daily_counter[day] += count\n",
    "        station_to_time_series[station] = sorted(daily_counter.items())\n",
    "    return station_to_time_series\n",
    "\n",
    "\n",
    "station_to_daily_time_series = reduce_booth_time_series_to_stations(booth_to_daily_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pprint(station_to_daily_time_series['14 ST-UNION SQ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 7\n",
    "- Plot the time series for a station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_station_time_series(station_name, station_to_daily_time_series):\n",
    "    time_series = station_to_daily_time_series[station_name]\n",
    "    days, counts = zip(*time_series)\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(days,counts)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of turnstile entries')\n",
    "    plt.title('Daily entries for station %s' % station_name)\n",
    "    \n",
    "plot_station_time_series('14 ST-UNION SQ', station_to_daily_time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 8\n",
    "- Make one list of counts for **one** week for one station. Monday's count, Tuesday's count, etc. so it's a list of 7 counts.\n",
    "Make the same list for another week, and another week, and another week.\n",
    "`plt.plot(week_count_list)` for every `week_count_list` you created this way. You should get a rainbow plot of weekly commute numbers on top of each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def separate_weeks(time_series):\n",
    "    time_series_for_each_week = []\n",
    "    week = []\n",
    "    for i, (day, count) in enumerate(time_series):\n",
    "        week.append( (day,count) )\n",
    "        # every 7 days, start a new week\n",
    "        # (do this on the last day of the current week)\n",
    "        if i%7 == 6:\n",
    "            time_series_for_each_week.append(week)\n",
    "            week = []\n",
    "    # at the end of the for loop, if there are some left\n",
    "    # over, put this partial week as the last (partial) week\n",
    "    time_series_for_each_week.append(week)\n",
    "    return time_series_for_each_week\n",
    "\n",
    "\n",
    "def rainbow_plot_for_station(station_name, station_to_daily_time_series):\n",
    "    time_series = station_to_daily_time_series[station_name]\n",
    "    time_series_for_each_week = separate_weeks(time_series)\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for week in time_series_for_each_week:\n",
    "        days, counts = zip(*week)\n",
    "        days = range(len(counts))\n",
    "        plt.plot(days,counts)\n",
    "    plt.xlabel('Day of the week')\n",
    "    plt.ylabel('Number of turnstile entries')\n",
    "    plt.xticks(np.arange(7),['St','Sn','Mo','Tu','We','Th','Fr'])\n",
    "    plt.title('Ridership per day for station %s'%station_name)\n",
    "    \n",
    "    \n",
    "rainbow_plot_for_station('14 ST-UNION SQ', station_to_daily_time_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 9\n",
    "- Over multiple weeks, sum total ridership for each station and sort them, so you can find out the stations with the highest traffic during the time you investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def total_traffic(time_series):\n",
    "    return sum([count for day,count in time_series])\n",
    "\n",
    "def station_time_series_item_to_station_total_traffic(item):\n",
    "    station, time_series = item\n",
    "    return total_traffic(time_series), station\n",
    "\n",
    "traffic_report = list(map(station_time_series_item_to_station_total_traffic,\n",
    "                 station_to_daily_time_series.items()))\n",
    "\n",
    "for tot_traffic, station in sorted(traffic_report, reverse=True)[:30]:\n",
    "    print('%-18s %s' % (station, tot_traffic))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 10\n",
    "- Make a single list of these total ridership values and plot it with `plt.hist(total_ridership_counts)` to get an idea about the distribution of total ridership among different stations.   \n",
    "This should show you that most stations have a small traffic, and the histogram bins for large traffic volumes have small bars.\n",
    "\n",
    "*Additional Hint*:    \n",
    "If you want to see which stations take the meat of the traffic, you can sort the total ridership counts and make a `plt.bar` graph. For this, you want to have two lists: the indices of each bar, and the values. The indices can just be `0,1,2,3,...`, so you can do \n",
    "\n",
    "    indices = range(len(total_ridership_values))\n",
    "    plt.bar(indices, total_ridership_values)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_ridership_counts = [ridership for ridership, station in traffic_report]\n",
    "plt.figure(figsize=(15,5))\n",
    "hist = plt.hist(total_ridership_counts, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, ok, the majority of the stations fall into the first bins with lower counts.   \n",
    "We can't see a lot of detail.   \n",
    "To get a better understanding, let's look at the histogram of log counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "log_counts = [math.log10(count) for count in total_ridership_counts]\n",
    "plt.figure(figsize=(15,5))\n",
    "n,bins,patches = hist = plt.hist(log_counts, bins=15)\n",
    "\n",
    "# Labels for the logarithmic x axis\n",
    "def log_count_to_label(log_count):\n",
    "    if log_count <= 6:\n",
    "        return '%.0f Thousand' % 10**(log_count-3)\n",
    "    else:\n",
    "        return '%.1f Million' % 10**(log_count-6)\n",
    "    \n",
    "tick_labels = map(log_count_to_label, bins)\n",
    "ticks = plt.xticks(bins, tick_labels, rotation=70)\n",
    "plt.xlabel(\"Total ridership count\")\n",
    "plt.ylabel(\"Number of stations with this total count\")\n",
    "plt.title(\"Distribution of ridership among\\n\"\n",
    "          \"NYC subway stations between\\n\"\n",
    "          \"Jan 3 to Jan 24, 2015\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you switch the y axis to logarithmic as well, you can see even more detail, but you lose some readability.   \n",
    "You can do this by setting\n",
    "\n",
    "    log=True\n",
    "    \n",
    "in the `plt.hist()` call. Below I copy paste the same code with only this difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_counts = [math.log10(count) for count in total_ridership_counts]\n",
    "plt.figure(figsize=(15,5))\n",
    "n,bins,patches = hist = plt.hist(log_counts, log=True, bins = 12)\n",
    "tick_labels = map(log_count_to_label, bins)\n",
    "ticks = plt.xticks(bins, tick_labels, rotation=70)\n",
    "plt.xlabel(\"Total ridership count\")\n",
    "plt.ylabel(\"Number of stations with this total count\")\n",
    "plt.title(\"Distribution of ridership among\\n\"\n",
    "          \"NYC subway stations between\\n\"\n",
    "          \"Jan 3 to Jan 24, 2015\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This really does not add much. But if one of the peaks dominated and you couldn't see the other peaks, using a log scale for the y axis would have helped.\n",
    "\n",
    "And finally, the bar graph mentioned in the _Additional Hint_ for the top 30 stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_stations = sorted(traffic_report, reverse=True)[:30]\n",
    "counts, stations = zip(*top_stations)\n",
    "indices = range(len(counts))\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(indices, counts)\n",
    "ticks = plt.xticks(indices, stations, rotation=70)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
